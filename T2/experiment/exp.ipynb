{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c53fb8-fddd-4499-a419-e1c3de6b2ebd",
   "metadata": {},
   "source": [
    "# Experimentos y análisis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63682ba9-7862-497b-a753-ec987673e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "CONVEX_HULL_EXEC = \"../build/structures\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1834210-2c63-4d11-b6fd-852ab8409c09",
   "metadata": {},
   "source": [
    "## Experimento 1\n",
    "Variar el tamaño del arreglo con `block_size` y `grid_size` fijos\n",
    "\n",
    "- Párametros:\n",
    "    - $N$: De $2^5$ a $2^{20}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f13cfb8-ff0d-4610-ad99-146fcfe51f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for size 10\n",
      "Running for size 100\n",
      "Running for size 1000\n",
      "Running for size 10000\n",
      "Running for size 100000\n",
      "Running for size 1000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rnge = 60000.0\n",
    "pcnt = 0.0\n",
    "for i in range(1, 7):\n",
    "    size = 10**i\n",
    "    print(\"Running for size\", size)\n",
    "    # do 10 runs for each size\n",
    "    for _ in range(10):\n",
    "        subprocess.run([CONVEX_HULL_EXEC, \"1\", str(size), str(rnge), str(pcnt)], stdout=subprocess.DEVNULL)\n",
    "        subprocess.run([CONVEX_HULL_EXEC, \"2\", str(size), str(rnge), str(pcnt)], stdout=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b7f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for size 10\n",
      "Running for size 100\n",
      "Running for size 1000\n",
      "Running for size 10000\n"
     ]
    }
   ],
   "source": [
    "rnge = 60000.0\n",
    "for i in range(1, 7):\n",
    "    pcnt = 0.1\n",
    "    size = 10**i\n",
    "    print(\"Running for size\", size)\n",
    "    # do 10 runs for each size\n",
    "    for _ in range(10):\n",
    "        for _ in range(10):\n",
    "            subprocess.run([CONVEX_HULL_EXEC, \"3\", str(size), str(rnge), str(pcnt)], stdout=subprocess.DEVNULL)\n",
    "            subprocess.run([CONVEX_HULL_EXEC, \"4\", str(size), str(rnge), str(pcnt)], stdout=subprocess.DEVNULL)\n",
    "        pcnt+=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4f7c6",
   "metadata": {},
   "source": [
    "### Análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = pd.read_csv(\"nbody_naive_cpu.csv\", header=None)\n",
    "\n",
    "naive_cl = pd.read_csv(\"nbody_naive_cl.csv\", header=None)\n",
    "local_mem_cl = pd.read_csv(\"nbody_local_mem_cl.csv\", header=None)\n",
    "bidimensional_cl = pd.read_csv(\"nbody_bidimensional_cl.csv\", header=None)\n",
    "\n",
    "cpu.columns = [\"size\", \"data creation time\", \"execution time\", \"total time\"]\n",
    "\n",
    "cl_columns = [\"size\", \"local size\", \"global size\", \"local size y\", \"global size y\", \"local mem size\", \"create data time\", \"copy to device\", \"execution time\", \"copy to host\"]\n",
    "naive_cl.columns = cl_columns\n",
    "local_mem_cl.columns = cl_columns\n",
    "bidimensional_cl.columns = cl_columns\n",
    "\n",
    "naive_cl[\"total time\"] = naive_cl[\"create data time\"] + naive_cl[\"copy to device\"] + naive_cl[\"execution time\"] + naive_cl[\"copy to host\"]\n",
    "local_mem_cl[\"total time\"] = local_mem_cl[\"create data time\"] + local_mem_cl[\"copy to device\"] + local_mem_cl[\"execution time\"] + local_mem_cl[\"copy to host\"]\n",
    "bidimensional_cl[\"total time\"] = bidimensional_cl[\"create data time\"] + bidimensional_cl[\"copy to device\"] + bidimensional_cl[\"execution time\"] + bidimensional_cl[\"copy to host\"]\n",
    "\n",
    "# cuda.columns = [\"size\", \"block size\", \"grid size\", \"data creation time\", \"copy to device time\", \"execution time\", \"copy to host time\", \"total time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4910b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot avg total time for each size\n",
    "cpu_avg = cpu.groupby(\"size\").mean()\n",
    "naive_cl_avg = naive_cl.groupby(\"size\").mean()\n",
    "local_mem_cl_avg = local_mem_cl.groupby(\"size\").mean()\n",
    "bidimensional_cl_avg = bidimensional_cl.groupby(\"size\").mean()\n",
    "\n",
    "# cuda_avg = cuda.groupby(\"size\").mean()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cpu_avg.index, cpu_avg[\"total time\"], label=\"CPU\")\n",
    "ax.plot(naive_cl_avg.index, naive_cl_avg[\"total time\"], label=\"OpenCL-Naive\")\n",
    "ax.plot(local_mem_cl_avg.index, local_mem_cl_avg[\"total time\"], label=\"OpenCL-Shared Memory\")\n",
    "ax.plot(bidimensional_cl_avg.index, bidimensional_cl_avg[\"total time\"], label=\"OpenCL-2D\")\n",
    "# ax.plot(cuda_avg.index, cuda_avg[\"total time\"], label=\"CUDA\")\n",
    "ax.set_xlabel(\"Size\")\n",
    "ax.set_ylabel(\"Total time (ms)\")\n",
    "ax.legend()\n",
    "plt.title(\"Total time for different sizes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10347b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot avg execution time for each size\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cpu_avg.index, cpu_avg[\"execution time\"], label=\"CPU\")\n",
    "ax.plot(naive_cl_avg.index, naive_cl_avg[\"execution time\"], label=\"OpenCL\")\n",
    "ax.plot(local_mem_cl_avg.index, local_mem_cl_avg[\"execution time\"], label=\"OpenCL\")\n",
    "ax.plot(bidimensional_cl_avg.index, bidimensional_cl_avg[\"execution time\"], label=\"OpenCL\")\n",
    "# ax.plot(cuda_avg.index, cuda_avg[\"execution time\"], label=\"CUDA\")\n",
    "ax.set_xlabel(\"Size\")\n",
    "ax.set_ylabel(\"Execution time (ms)\")\n",
    "ax.legend()\n",
    "plt.title(\"Execution time for different sizes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f621e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print speedup on execution time\n",
    "speedup_naive_cl = cpu_avg[\"execution time\"] / naive_cl_avg[\"execution time\"]\n",
    "speedup_shared_cl = cpu_avg[\"execution time\"] / local_mem_cl_avg[\"execution time\"]\n",
    "speedup_bidimensional_cl = cpu_avg[\"execution time\"] / bidimensional_cl_avg[\"execution time\"]\n",
    "# speedup_cuda = cpu_avg[\"execution time\"] / cuda_avg[\"execution time\"]\n",
    "\n",
    "print(\"Speedup Naive OpenCL\")\n",
    "print(speedup_naive_cl)\n",
    "print(\"Speedup Shared Memory OpenCL\")\n",
    "print(speedup_shared_cl)\n",
    "print(\"Speedup Bidimensional Mapping OpenCL\")\n",
    "print(speedup_bidimensional_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa404f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_avg[\"data creation time\"] /= cl_avg.index\n",
    "cl_avg[\"copy to device time\"] /= cl_avg.index\n",
    "cl_avg[\"execution time\"] /= cl_avg.index\n",
    "cl_avg[\"copy to host time\"] /= cl_avg.index\n",
    "\n",
    "cuda_avg[\"data creation time\"] /= cuda_avg.index\n",
    "cuda_avg[\"copy to device time\"] /= cuda_avg.index\n",
    "cuda_avg[\"execution time\"] /= cuda_avg.index\n",
    "cuda_avg[\"copy to host time\"] /= cuda_avg.index\n",
    "\n",
    "# plot a two pie chart of the average time spent on each step for OpenCL and CUDA\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].pie(cl_avg.iloc[0][3:6], labels=cl_avg.columns[3:6], autopct='%1.1f%%')\n",
    "ax[0].set_title(\"OpenCL\")\n",
    "ax[1].pie(cuda_avg.iloc[0][3:6], labels=cuda_avg.columns[3:6], autopct='%1.1f%%')\n",
    "ax[1].set_title(\"CUDA\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cc073",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "- Para arreglos de tamaño menor o igual a $2^{20}$ el rendimiento en CPU y GPU es similar\n",
    "- Existen un gran speedup en *tiempo de ejecución* no asi en *tiempo total* del programa\n",
    "- En OpenCL el mayor problema esta en el paso de memoria de CPU a GPU.\n",
    "- En CUDA también se repite este problema pero esta más equilibrado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
